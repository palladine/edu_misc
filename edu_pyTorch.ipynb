{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd54383",
   "metadata": {},
   "source": [
    "### **Основные модули PyTorch:**\n",
    "* torch.nn\n",
    "    * torch.nn.DataParallel\n",
    "* torch.distributed\n",
    "* torch.optim\n",
    "* torch.utils\n",
    "    * torch.utils.data\n",
    "        * Классы: DataSet, DataLoader\n",
    "* torch.autograd\n",
    "* torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fda3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e25f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225f7d8",
   "metadata": {},
   "source": [
    "### **Тензоры**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e43311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(7) # скаляр, 0-dimensions\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dc19aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor(9).item()  # получение значения скаляра\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09141032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([1,3,5,7]) # 1-dimension\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9dd25bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 5, 7, 9],\n",
      "        [2, 4, 6, 8, 0]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([[1,3,5,7,9], [2,4,6,8,0]]) # 2-dimensions\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b57c1131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[11, 12, 13],\n",
      "         [14, 15, 16]]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.tensor([[[1,2,3],[4,5,6]],[[11,12,13],[14,15,16]]]) # 3-dimensions\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11635714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68728f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "b = torch.zeros(6)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16991e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([1,2,3,4,5])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be899c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0373, 0.5573],\n",
      "        [0.3250, 0.7951]])\n"
     ]
    }
   ],
   "source": [
    "d1 = torch.rand(2,2) # тензор случайных чисел размерности 2x2\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71aa0bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6478,  0.9908,  0.6877],\n",
      "        [-3.0446, -1.5172, -0.3388],\n",
      "        [ 1.9928, -1.2252,  1.8098]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.randn(3,3)   # тензор случайных чисел (нормальное распределение) размерности 3x3\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01c5c744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.0000, 11.4286, 12.8571, 14.2857, 15.7143, 17.1429, 18.5714, 20.0000,\n",
      "        21.4286, 22.8571, 24.2857, 25.7143, 27.1429, 28.5714, 30.0000])\n"
     ]
    }
   ],
   "source": [
    "e = torch.linspace(10,30,15)  # тензор от 10 до 30 из 15 чисел, между числами равное расстояние\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75ac9e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,3,5)  # размерность 2x3x5\n",
    "print(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e60af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.eye(5)   # матрица идентичности\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90aee9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],[[21,22,23,24,25],[26,27,28,29,30],[31,32,33,34,35]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58e859f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)  # размерность тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe2b681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "r = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(r)\n",
    "print(r.reshape(1, 6))   # изменение размерностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "400e237b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(r.reshape(-1, 2))  # -1 указывает на авто подбор количества элементов в первой размерности, сравни пример ниже!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f98f8962",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 2]' is invalid for input of size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MAXIM~1.DUR\\AppData\\Local\\Temp/ipykernel_7780/3936626806.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 2]' is invalid for input of size 6"
     ]
    }
   ],
   "source": [
    "print(r.reshape(1, 2))   # здесь ошибка, 1 - явно указана первая размерность, итог (1*2 = 2 элемента) должно быть 6!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbe042cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(c[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47de6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21, 22, 23, 24, 25],\n",
      "        [26, 27, 28, 29, 30],\n",
      "        [31, 32, 33, 34, 35]])\n"
     ]
    }
   ],
   "source": [
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e17a5e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25)\n"
     ]
    }
   ],
   "source": [
    "print(a[1,0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2518d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10],\n",
      "         [11, 12, 13, 14, 15]],\n",
      "\n",
      "        [[21, 22, 23, 24, 25],\n",
      "         [26, 27, 28, 29, 30],\n",
      "         [31, 32, 33, 34, 35]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d15c7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8,  9],\n",
      "        [13, 14]])\n"
     ]
    }
   ],
   "source": [
    "print(a[0,1:,2:4])   # срезы для трех размерностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "956d2cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3,4,5], dtype=torch.float64)   # указание типа данных\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c73e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cpu')  # тензор для CPU\n",
    "# tensor_gpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cuda')  # тензор для GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368bdd8",
   "metadata": {},
   "source": [
    "#### Арифметические операции над тензорами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac7d66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1,2,3,4,5])\n",
    "t2 = torch.tensor([11,12,13,14,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48eef99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 14, 16, 18, 20])\n"
     ]
    }
   ],
   "source": [
    "print(t1+t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbc6a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 10, 10, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cab64157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  4,  6,  8, 10])\n"
     ]
    }
   ],
   "source": [
    "print(t1*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0eede43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 10, 15],\n",
      "        [20, 25, 30]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "t6 = torch.tensor(5)\n",
    "print(t5*t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df46a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6667, 4.0000, 4.3333, 4.6667, 5.0000])\n"
     ]
    }
   ],
   "source": [
    "print(t2 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9373c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.0000,  6.0000,  4.3333,  3.5000,  3.0000])\n"
     ]
    }
   ],
   "source": [
    "print(t2 / t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2e190a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "print(t2 % 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebb53370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4,  6,  8, 10],\n",
      "        [ 4,  8, 12, 16, 20],\n",
      "        [ 6, 12, 18, 24, 30],\n",
      "        [ 8, 16, 24, 32, 40],\n",
      "        [ 0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "# Умножение матриц\n",
    "t3 = torch.tensor([[2],[4],[6],[8],[0]])\n",
    "t4 = torch.tensor([[1,2,3,4,5]])\n",
    "print(torch.mm(t3, t4))                 # (5x1)*(1x5) = 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76d2a178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8415,  0.9093,  0.1411, -0.7568, -0.9589])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sin(t1))     # также cos, tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44756d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "# расчет производной в точке x\n",
    "x = torch.tensor([1.5], requires_grad=True).float()  # точка x, отслеживание градиентов в тензоре \n",
    "y = x**2   # парабола\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b67172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22f6fb83f40>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# расчет производной в точках\n",
    "x = torch.linspace(-5,5,100,  requires_grad=True).float()\n",
    "y = x**2\n",
    "xn = x.detach().numpy()\n",
    "yn = xn**2\n",
    "\n",
    "# function\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xn, yn)\n",
    "# derivative function\n",
    "y.backward(torch.ones_like(y))\n",
    "xd = x.grad.detach().numpy()\n",
    "ax.plot(xn, xd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1575fc4",
   "metadata": {},
   "source": [
    "### Функции применимые к тензорам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc68edc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6935, 0.0416, 0.2711, 0.8617, 0.5135, 0.1037],\n",
      "        [0.7548, 0.3679, 0.7392, 0.1543, 0.6249, 0.7748],\n",
      "        [0.1994, 0.8422, 0.2610, 0.0664, 0.6224, 0.6686],\n",
      "        [0.0170, 0.2343, 0.6072, 0.5088, 0.2412, 0.9335],\n",
      "        [0.6409, 0.6917, 0.9349, 0.0330, 0.2880, 0.3101],\n",
      "        [0.7597, 0.5446, 0.9669, 0.2313, 0.6460, 0.3247]])\n",
      "tensor(0.9669)\n",
      "0.9669411778450012\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(6,6)\n",
    "print(a)\n",
    "print(a.max())           # максимальный элемент\n",
    "print(a.max().item())    # значение\n",
    "print(a.argmax().item()) # значение индекса максимального элемента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a54d57ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1763, -1.3824],\n",
      "         [-0.0982,  0.2172],\n",
      "         [-0.7888,  0.0776],\n",
      "         [ 0.1917, -1.3143]],\n",
      "\n",
      "        [[-0.0239,  1.6421],\n",
      "         [ 0.0026, -0.4804],\n",
      "         [ 1.1101,  0.3640],\n",
      "         [ 0.7545,  0.9978]],\n",
      "\n",
      "        [[ 0.0741,  0.9124],\n",
      "         [-0.5444, -1.9301],\n",
      "         [-1.6596, -1.7160],\n",
      "         [ 0.1296, -0.8660]],\n",
      "\n",
      "        [[ 0.1991,  0.9172],\n",
      "         [ 2.1126, -0.5568],\n",
      "         [-0.2204, -0.1752],\n",
      "         [-0.1131,  0.1206]],\n",
      "\n",
      "        [[ 1.5923,  2.0426],\n",
      "         [ 0.7942,  0.4707],\n",
      "         [ 1.0939,  0.1272],\n",
      "         [ 0.2721,  0.1248]]])\n",
      "tensor([[[ 0.1763, -0.0239,  0.0741,  0.1991,  1.5923],\n",
      "         [-0.0982,  0.0026, -0.5444,  2.1126,  0.7942],\n",
      "         [-0.7888,  1.1101, -1.6596, -0.2204,  1.0939],\n",
      "         [ 0.1917,  0.7545,  0.1296, -0.1131,  0.2721]],\n",
      "\n",
      "        [[-1.3824,  1.6421,  0.9124,  0.9172,  2.0426],\n",
      "         [ 0.2172, -0.4804, -1.9301, -0.5568,  0.4707],\n",
      "         [ 0.0776,  0.3640, -1.7160, -0.1752,  0.1272],\n",
      "         [-1.3143,  0.9978, -0.8660,  0.1206,  0.1248]]])\n"
     ]
    }
   ],
   "source": [
    "# изменение размера\n",
    "b = torch.randn(5,4,2)\n",
    "print(b)\n",
    "b = b.permute(2,1,0)   # указать по индексам\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f2dd8",
   "metadata": {},
   "source": [
    "## Однослойная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "667f6581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4051]])\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "inputs_layer = torch.randn((1,10)) # входной слой - матрица 1x10\n",
    "weights = torch.randn((1,10))      # веса - матрица 1x10\n",
    "b = 1   # смещение\n",
    "\n",
    "weights_reshape = weights.reshape(10,1)  # изменение формы матрицы к 10x1 для следующего умножения, \n",
    "                                         # либо транспонирование матрицы weights.T\n",
    "\n",
    "output = sigmoid(torch.mm(inputs_layer, weights_reshape)+b) # выходной нейрон\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90859dcd",
   "metadata": {},
   "source": [
    "## Шаг 1. Набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "train_data_path = \"./train/\"              # путь к тренировочным изображениям \n",
    "test_data_path = \"./test/\"                # путь к тестовым изображениям\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(64),      # масштабирование всех изображений в 64x64\n",
    "    transforms.ToTensor(),      # перевод в тензор\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.405], std=[0.229, 0.224, 0.225])  # нормализация\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4c474",
   "metadata": {},
   "source": [
    "## Шаг 2. Загрузчик данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451eae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=batch_size)\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e533d",
   "metadata": {},
   "source": [
    "## Шаг 3. Нейронная сеть со слоями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()       # конструктор суперкласса\n",
    "                                          # создание слоев\n",
    "        self.fc1 = nn.Linear(12288, 84)   # 12288 = 64*64*3 (трехмерный ранее преобразовали в одномерный тензор)\n",
    "                                          # входной слой, на выходе 84 нейрона\n",
    "        self.fc2 = nn.Linear(84, 50)      # вход - 84 нейрона, выход - 50\n",
    "        self.fc3 = nn.Linear(50, 2)       # вход - 50 нейронов, выход - 2\n",
    "        \n",
    "    def forward(self):\n",
    "        x = x.view(-1, 12288)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "exemple = NeuNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1d300",
   "metadata": {},
   "source": [
    "## Шаг 4. Оптимизатор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce2f5b",
   "metadata": {},
   "source": [
    "Обучение сети включает в себя передачу данных через сеть, использование функции потерь для определения \n",
    "разности между прогнозом и фактической маркировкой, а затем использование этой информации для обновления \n",
    "весов сети, чтобы возврат функции потерь был как можно меньше. Для выполнения обновлений в нейронной сети \n",
    "используется оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b86275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "...\n",
    "optimizer = optim.Adam(exemple.parameters(), lr=0.001) # оптимизатор Adam, lr - скорость обучения\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0cd45",
   "metadata": {},
   "source": [
    "## Шаг 5. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):               # по эпохам\n",
    "    for batch in train_loader:            # по частям (пакетами) обучающей выборки \n",
    "        optimizer.zero_grad()             # обнуление градиентов на каждой итерации\n",
    "        input, target = batch\n",
    "        output = model(input)             # через модель нейронной сети \n",
    "        loss = loss_fn(output, target)    # функция потерь (на вход полученные данные и целевые данные)\n",
    "        loss.backward()                   # расчет градиентов\n",
    "        optimizer.step()                  # расчет новых весов на основе полученных градиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4ac82",
   "metadata": {},
   "source": [
    "### ШАГ 6. ИТОГ\n",
    "````python\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"): \n",
    "    for epoch in range(epochs): \n",
    "        training_loss = 0.0 \n",
    "        valid_loss = 0.0 \n",
    "        model.train() \n",
    "        for batch in train_loader: \n",
    "            optimizer.zero_grad() \n",
    "            inputs, target = batch \n",
    "            inputs = inputs.to(device) \n",
    "            target = targets.to(device) \n",
    "            output = model(inputs) \n",
    "            loss = loss_fn(output, target) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            training_loss += loss.data.item() \n",
    "            training_loss /= len(train_iterator) \n",
    "            model.eval() \n",
    "            num_correct = 0 \n",
    "            num_examples = 0 \n",
    "        for batch in val_loader: \n",
    "            inputs, targets = batch \n",
    "            inputs = inputs.to(device) \n",
    "            output = model(inputs) \n",
    "            targets = targets.to(device) \n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() \n",
    "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], target).view(-1) \n",
    "            num_correct += torch.sum(correct).item() \n",
    "            num_examples += correct.shape[0] \n",
    "            valid_loss /= len(valid_iterator) \n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.\n",
    "        format(epoch, training_loss, valid_loss, num_correct / num_examples)) \n",
    "\n",
    "# torch.nn.CrossEntropyLoss() - сама функция потерь \n",
    "train(exemple, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, test_data_loader, device)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f96090",
   "metadata": {},
   "source": [
    "## Шаг 7. Прогнозирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "img = transform(img)\n",
    "prediction = exemple(img)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3519b0",
   "metadata": {},
   "source": [
    "# Сверточные нейроные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b702b938",
   "metadata": {},
   "source": [
    "Идея свёрточных нейронных сетей заключается в чередовании свёрточных слоёв (англ. convolution layers) и субдискретизирующих слоёв (англ. subsampling layers или англ. pooling layers, слоёв подвыборки). Структура сети — однонаправленная (без обратных связей), принципиально многослойная. Для обучения используются стандартные методы, чаще всего метод обратного распространения ошибки. Функция активации нейронов (передаточная функция) — любая, по выбору исследователя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddc8b1",
   "metadata": {},
   "source": [
    "#### Свертки в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37777e0d",
   "metadata": {},
   "source": [
    "___\n",
    "**Conv2d - двумерная свертка**  \n",
    "  \n",
    "Синтаксис: **nn.Conv2d(in_ch, out_ch, kern_size, stride, padding)**  \n",
    "**in_ch** - количество входных каналов (для RGB - это 3)   \n",
    "**out_ch** - количество выходных каналов (количество фильтров в слое)  \n",
    "**kern_size** - размер ядра (фильтра) (либо кортеж, либо скаляр задающий квадрат)  \n",
    "**stride** - на какое количество шагов продвигаться ядром при свертке, для создания карты признаков. Можно передать кортеж *(a, b)* - что позволяет перемещать ядро на *a* поперек и *b* вниз на каждой итерации  \n",
    "**padding** - отступ от краев, можно также передать кортеж (height, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784aaf7",
   "metadata": {},
   "source": [
    "___\n",
    "**Слои пулинга (субдискретизации)**  \n",
    "Эти слои снижают разрешение сети от предыдущего входного слоя, что дает нам меньше параметров на нижних слоях.  \n",
    "Такое сжатие приводит к более быстрым вычислениям вначале и помогает предотвратить переобучение сети.  \n",
    "  \n",
    "Синтаксис: **nn.MaxPool2d(kern_size, stride)**  \n",
    "**kern_size** - размер ядра (фильтра) (либо кортеж, либо скаляр задающий квадрат)  \n",
    "**stride** - на какое количество шагов продвигаться ядром  \n",
    "Пример:  \n",
    "Вход 5x3 при размере ядра 3x3 и шага 2 на выходе получим два тензора 3x3, в *MaxPool* мы берем *максимальное* значение каждого из этих тензоров, что дает выходной тензор 1x2.  \n",
    "  \n",
    "Синтаксис: **nn.AvgPool()**  \n",
    "Синтаксис: **nn.AdaptiveMaxPool2d()**  \n",
    "Синтаксис: **nn.AdaptiveAvgPool2d()**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6a2fa",
   "metadata": {},
   "source": [
    "___\n",
    "**Dropout (прореживание)**  \n",
    "Синтаксис: **nn.Dropout(p=0.2)**  \n",
    "При *p=0.2* 20% входного тензора обнуляется случайным образом.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45011141",
   "metadata": {},
   "source": [
    "___\n",
    "**BatchNorm (пакетная нормализация)**  \n",
    "Это простой слой с единственной задачей: убедиться, что каждый мини-пакет, проходящий через сеть, имеет нулевое математическое ожидание и единичную дисперсию. Для небольших сетей BatchNorm действительно менее полезен, но по мере их увеличения влияние любого слоя на другой слой, может быть значительным из-за многократного умножения, и вы можете получить либо исчезающие, либо взрывающиеся градиенты. Слои BatchNorm гарантируют, что умножения внутри вашей сети не выйдут из-под контроля.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106a995",
   "metadata": {},
   "source": [
    "## Работа со встроенными моделями нейронных сетей в PyTorch\n",
    "````python  \n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# модель resnet\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# заморозка слоев\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# заморозка всех слоев кроме слоев BatchNorm\n",
    "# for name, param in transfer_model.named_parameters():\n",
    "#     if(\"bn\" not in name):\n",
    "#         param.requires_grad = False\n",
    "\n",
    "    \n",
    "# изменение слоя классификатора модели\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(500, 2)\n",
    ")\n",
    "\n",
    "print(model)\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b227d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
